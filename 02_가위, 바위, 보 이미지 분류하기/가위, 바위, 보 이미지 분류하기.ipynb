{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 가위, 바위, 보 이미지 분류하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#문제-정의\" data-toc-modified-id=\"문제-정의-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>문제 정의</a></span></li><li><span><a href=\"#데이터-준비\" data-toc-modified-id=\"데이터-준비-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>데이터 준비</a></span><ul class=\"toc-item\"><li><span><a href=\"#사이즈-변경하기\" data-toc-modified-id=\"사이즈-변경하기-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>사이즈 변경하기</a></span></li><li><span><a href=\"#데이터-라벨링-하기\" data-toc-modified-id=\"데이터-라벨링-하기-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>데이터 라벨링 하기</a></span></li><li><span><a href=\"#데이터-시각화\" data-toc-modified-id=\"데이터-시각화-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>데이터 시각화</a></span></li></ul></li><li><span><a href=\"#모델-구현-및-학습\" data-toc-modified-id=\"모델-구현-및-학습-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>모델 구현 및 학습</a></span></li><li><span><a href=\"#검증\" data-toc-modified-id=\"검증-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>검증</a></span></li><li><span><a href=\"#테스트\" data-toc-modified-id=\"테스트-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>테스트</a></span></li><li><span><a href=\"#튜닝\" data-toc-modified-id=\"튜닝-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>튜닝</a></span><ul class=\"toc-item\"><li><span><a href=\"#바꿔-볼-수-있는-하이퍼파라미터들\" data-toc-modified-id=\"바꿔-볼-수-있는-하이퍼파라미터들-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>바꿔 볼 수 있는 하이퍼파라미터들</a></span><ul class=\"toc-item\"><li><span><a href=\"#기본-하이퍼파라미터\" data-toc-modified-id=\"기본-하이퍼파라미터-6.1.1\"><span class=\"toc-item-num\">6.1.1&nbsp;&nbsp;</span>기본 하이퍼파라미터</a></span></li><li><span><a href=\"#n_channel_1\" data-toc-modified-id=\"n_channel_1-6.1.2\"><span class=\"toc-item-num\">6.1.2&nbsp;&nbsp;</span>n_channel_1</a></span></li><li><span><a href=\"#n_channel_2\" data-toc-modified-id=\"n_channel_2-6.1.3\"><span class=\"toc-item-num\">6.1.3&nbsp;&nbsp;</span>n_channel_2</a></span></li><li><span><a href=\"#n_dense\" data-toc-modified-id=\"n_dense-6.1.4\"><span class=\"toc-item-num\">6.1.4&nbsp;&nbsp;</span>n_dense</a></span></li><li><span><a href=\"#epoch\" data-toc-modified-id=\"epoch-6.1.5\"><span class=\"toc-item-num\">6.1.5&nbsp;&nbsp;</span>epoch</a></span></li></ul></li></ul></li><li><span><a href=\"#회고\" data-toc-modified-id=\"회고-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>회고</a></span><ul class=\"toc-item\"><li><span><a href=\"#느낀점\" data-toc-modified-id=\"느낀점-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>느낀점</a></span></li><li><span><a href=\"#아쉬웠던-점\" data-toc-modified-id=\"아쉬웠던-점-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>아쉬웠던 점</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 정의\n",
    "\n",
    "가위, 바위, 보 이미지 데이터를 사용해서 이미지 속의 가위, 바위, 보를 분류해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비\n",
    "\n",
    "구글에 있는 데이터 셋을 사용했다. 데이터는 아래의 링크에서 내려받을 수 있다.\n",
    "\n",
    "+ train data https://storage.googleapis.com/download.tensorflow.org/data/rps.zip\n",
    "+ test data https://storage.googleapis.com/download.tensorflow.org/data/rps-test-set.zip\n",
    "\n",
    "train data는 가위, 바위, 보 각 840개씩 총 2520개, test data는 각 124개씩 총 372개의 이미지 파일로 구성되어 있다.\n",
    "\n",
    "이미지 파일의 크기는 300x300이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사이즈 변경하기\n",
    "\n",
    "먼저, 가위의 이미지를 불러와서 이미지의 사이즈를 28x28로 변경해준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/ssac28/aiffel/rock_scissor_paper/scissor\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 png 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.png\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img=new_img.convert('RGB') # Pillow 라이브러리를 이용하여 RGB 로 다시 저장해준다.\n",
    "    new_img.save(img,\"png\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마찬가지로 바위와 보도 데이터를 28x28 사이즈로 다듬어준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/ssac28/aiffel/rock_scissor_paper/rock\n",
      "바위 이미지 resize 완료!\n",
      "이미지 디렉토리 경로:  /home/ssac28/aiffel/rock_scissor_paper/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 png 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.png\") \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img=new_img.convert('RGB') # Pillow 라이브러리를 이용하여 RGB 로 다시 저장해준다.\n",
    "    new_img.save(img,\"png\")\n",
    "    \n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 png 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.png\") \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img=new_img.convert('RGB') # Pillow 라이브러리를 이용하여 RGB 로 다시 저장해준다.\n",
    "    new_img.save(img,\"png\")\n",
    "    \n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 라벨링 하기\n",
    "\n",
    "입력으로 이미지가 있는 폴더 위치를 받는 함수를 만들어 3개의 클래스를 만들어 각 이미지 데이터에 라벨을 붙여준다.\n",
    "\n",
    "가위 : 0, 바위 : 1, 보 : 2로 라벨링된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 2520 입니다.\n",
      "x_train shape: (2520, 28, 28, 3)\n",
      "y_train shape: (2520,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=2520   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3 # 흑백 이미지의 경우 1, 컬러 이미지의 경우 3을 넣어준다.\n",
    "    \n",
    "    # 이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.png'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.png'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.png'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> glob 모듈\n",
    "\n",
    "glob 모듈은 유닉스 셸이 사용하는 규칙에 따라 지정된 패턴과 일치하는 모든 경로명을 찾습니다. 하지만 결과는 임의의 순서로 반환됩니다. 물결표(tilde) 확장은 수행되지 않지만, \\*, ? 및 []로 표시되는 문자 범위는 올바르게 일치합니다.\n",
    "\n",
    "이는 서브 셸을 실제로 호출하지 않고 os.scandir() 과 fnmatch.fnmatch() 함수를 사용하여 수행됩니다. fnmatch.fnmatch()와 달리, glob은 점(.)으로 시작하는 파일 이름을 특수한 경우로 취급합니다. (물결표와 셸 변수 확장은 os.path.expanduser() 와 os.path.expandvars()를 사용하십시오.)\n",
    "\n",
    "+ https://docs.python.org/ko/3/library/glob.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _iglob at 0x7f6c99b7b050>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# glob은 단순히 경로를 지정하는 것이 아니라 이터레이터로 만들어서 반환해준다.\n",
    "glob.iglob(os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"+'/scissor/*.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 시각화\n",
    "\n",
    "다듬은 이미지 데이터를 시각화해서 이미지를 확인해보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인덱스를 바꿔가며 확인해 본 결과, 라벨이 알맞게 붙은 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 구현 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델을 구현해보자.\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3))) # 흑백 이미지와는 달리 RGB가 3이므로 1이 아니라 3을 넣어준다.\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "총 7개의 layer를 가지고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.8089 - accuracy: 0.6619\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.2572 - accuracy: 0.9377\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.0837 - accuracy: 0.9837\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.9940\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.0184 - accuracy: 0.9984\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 0.9996\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6c94d8c5d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습하기\n",
    "# model.compile()과 model.fit()을 사용해 봅시다.\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=10) # epoch는 10으로 지정해줬다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 검증\n",
    "\n",
    "검증하기 위해 먼저 test data 또한 train data와 마찬가지로 데이터를 다듬어준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/ssac28/aiffel/rock_scissor_paper/test/scissor\n",
      "테스트 가위 이미지 resize 완료!\n",
      "이미지 디렉토리 경로:  /home/ssac28/aiffel/rock_scissor_paper/test/rock\n",
      "테스트 바위 이미지 resize 완료!\n",
      "이미지 디렉토리 경로:  /home/ssac28/aiffel/rock_scissor_paper/test/paper\n",
      "테스트 보 이미지 resize 완료!\n",
      "테스트 데이터(x_test)의 이미지 개수는 372 입니다.\n",
      "x_test shape: (372, 28, 28, 3)\n",
      "y_test shape: (372,)\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "# 가위\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\" # 테스트 데이터의 경로를 지정해준다.\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.png\")  \n",
    "\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img=new_img.convert('RGB')\n",
    "    new_img.save(img,\"png\")\n",
    "\n",
    "print(\"테스트 가위 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "# 바위\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.png\") \n",
    "\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img=new_img.convert('RGB')\n",
    "    new_img.save(img,\"png\")\n",
    "    \n",
    "print(\"테스트 바위 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "# 보\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.png\") \n",
    "\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img=new_img.convert('RGB')\n",
    "    new_img.save(img,\"png\")\n",
    "    \n",
    "print(\"테스트 보 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "\n",
    "# 마찬가지로 test data에도 라벨링을 해준다.\n",
    "def load_test_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=372   # 테스트 데이터의 총 개수\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.png'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.png'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.png'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"테스트 데이터(x_test)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_test_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 - 0s - loss: 0.5109 - accuracy: 0.8683\n",
      "test_loss: 0.5108973979949951 \n",
      "test_accuracy: 0.8682795763015747\n"
     ]
    }
   ],
   "source": [
    "# Hint! model.evaluate()을 사용해 봅시다.\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 튜닝\n",
    "\n",
    "+ 하이퍼파라미터들을 바꿔가며 결과 변화를 확인해보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_54 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_55 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_27 (Flatten)         (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 2.5647 - accuracy: 0.7615\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.0465 - accuracy: 0.9829\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.0096 - accuracy: 0.9988\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 8.1556e-04 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 6.3059e-04 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 5.2410e-04 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 4.5387e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 3.8399e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 3.1599e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 3.0236e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.4422e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.3584e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.1104e-04 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.7902e-04 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.7076e-04 - accuracy: 1.0000\n",
      "12/12 - 0s - loss: 1.5998 - accuracy: 0.6989\n",
      "test_loss: 1.5998181104660034 \n",
      "test_accuracy: 0.698924720287323\n"
     ]
    }
   ],
   "source": [
    "#바꿔 볼 수 있는 하이퍼파라미터들\n",
    "n_channel_1=16\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=20\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 바꿔 볼 수 있는 하이퍼파라미터들\n",
    "\n",
    "+ n_channel_1=16\n",
    "+ n_channel_2=32\n",
    "+ n_dense=32\n",
    "+ n_train_epoch=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기본 하이퍼파라미터\n",
    "\n",
    "1. loss: 2.4653 - accuracy: 0.7016\n",
    "2. loss: 2.9104 - accuracy: 0.6075\n",
    "3. loss: 1.2956 - accuracy: 0.7688\n",
    "4. loss: 3.5502 - accuracy: 0.6667\n",
    "5. loss: 2.6038 - accuracy: 0.6505"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n_channel_1\n",
    "\n",
    "+ 32\n",
    "\n",
    "1. loss: 1.1501 - accuracy: 0.7849\n",
    "2. loss: 1.2983 - accuracy: 0.6828\n",
    "3. loss: 1.7173 - accuracy: 0.7177\n",
    "4. loss: 1.9886 - accuracy: 0.6505\n",
    "5. loss: 1.3817 - accuracy: 0.7742"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n_channel_2\n",
    "\n",
    "+ 64\n",
    "\n",
    "1. loss: 1.1552 - accuracy: 0.7742\n",
    "2. loss: 1.2760 - accuracy: 0.7231\n",
    "3. loss: 1.5159 - accuracy: 0.7124\n",
    "4. loss: 1.6436 - accuracy: 0.7016\n",
    "5. loss: 0.5635 - accuracy: 0.7823"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n_dense\n",
    "\n",
    "+ 64\n",
    "\n",
    "1. loss: 1.6151 - accuracy: 0.7527\n",
    "2. loss: 1.7346 - accuracy: 0.7366\n",
    "3. loss: 1.2115 - accuracy: 0.6989\n",
    "4. loss: 3.0429 - accuracy: 0.5995\n",
    "5. loss: 0.7592 - accuracy: 0.7930"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### epoch\n",
    "\n",
    "+ 20\n",
    "\n",
    "1. loss: 1.1060 - accuracy: 0.8495\n",
    "2. loss: 3.9921 - accuracy: 0.5618\n",
    "3. loss: 1.0795 - accuracy: 0.7930\n",
    "4. loss: 1.0793 - accuracy: 0.7661\n",
    "5. loss: 1.5998 - accuracy: 0.6989"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하이퍼파라미터 4개를 하나씩 변경해서 5번씩 실행했다.\n",
    "\n",
    "횟수가 적어 정확하다고 할 수는 없지만, **n_channel_2**을 제외하고는 유의미한 변화를 느끼기는 힘들었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회고\n",
    "\n",
    "### 느낀점\n",
    "\n",
    "+ 직접 데이터를 만들어도 보고, 딥러닝 모델을 만들어 하이퍼파라미터를 하나씩 바꿔가며 결과를 비교해보는 것은 정말로 특별한 경험이었다.\n",
    "+ 단순히 복사, 붙여넣기가 아닌 직접 코드를 하나씩 쳐보며 음미했다. ~~*맛있다*~~\n",
    "+ 몰랐던, 막혔던 부분을 검색해가며 스스로 해결했을 때의 그 쾌감. 이 것 때문에 여기에 빠졌는지도 모르겠다.\n",
    "\n",
    "### 아쉬웠던 점\n",
    "\n",
    "+ 데이터\n",
    "    - 직접 만든 데이터로 모델을 실행했을 때 생각보다 결과가 좋지 않았다.\n",
    "    - 이미지 분류에서 데이터의 질이 얼마나 중요한지 다시 한번 느끼게 되었다.\n",
    "+ 모델\n",
    "    - 직접 모델을 만들어보고 했지만 사실 잘 모른다.\n",
    "    - 이 하이퍼파라미터가 어디에 어떤 영향을 미치는지, 또 레이어가 몇 개가 더 필요한지, 최적의 파라미터는 무엇인지\n",
    "    - 많은 공부가 필요하다고 느꼈다.\n",
    "    \n",
    "다음에는 더 성장하길!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
